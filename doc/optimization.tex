\chapter{Optimization: Lattice Correction and Design}
\label{c:opti}

\index{optimization|hyperbf}

``\vn{Optimization}'' is the process of varying model (\sref{s:lattice}) lattice parameters so that
a given set of properties are as close to given ``desired'' values as possible. Optimization
problems generally fall into one of two categories. One category involves ``\vn{lattice
correction}''. Problems in this category involve matching the \vn{model} lattice to actual measured
data.  For example, orbit flattening involves varying steering in the \vn{model} lattice so that the
orbit calculated from the \vn{model} lattice matches as close as possible the measured orbit. The
steering strengths in the \vn{model} lattice can then be used to calculate what changes are needed
to correct the orbit in the actual machine. This is discussed in
Section~\sref{s:lattice.correction}.

The other category of optimization problems involves ``lattice design'' where lattice parameters are
varied to achieve some set of ideal properties. For example, varying sextupole magnet strengths in
order to give maximum dynamic aperture. This is discussed in Section~\sref{s:lattice.design}.

%------------------------------------------------------------------------
\section{Optimization Overview}

Optimization involves ``\vn{data}'' and ``\vn{variables}''. \vn{Data} are the parameters to be
optimized. For example, orbit positions when flattening an orbit or the value of beta at the
interaction point when designing a lattice. \vn{Variables} are what is to be varied which can be steering
strengths, magnet positions, etc. 

How data is organized within \tao is discussed in detail in Chapter~\sref{c:data}. In brief, each
datum has a set of associated parameters. For example, each datum has ``\vn{model}'' and
``\vn{design}'' values which is the value of the datum as calculated from the \vn{model} and
\vn{design} lattices. Each datum also has a ``\vn{measured}'' value which is set by the User. This
value can be from an actual measurement which is typical when doing lattice correction or may be the
desired value of the datum which is typical when doing lattice design.

How variables are organized within \tao is discussed in detail in Chapter~\sref{c:var}. In brief,
like datums, each variable has a number of associated parameters. For example, each variable has a
``\vn{model}'' value which controls the corresponding value or values (a variable can control
multiple parameters simultaneously) in the \vn{model} lattice. There are also ``\vn{low_lim}'' and
``\vn{high_lim}'' values that can be set by the user that are used to keep the variable \vn{model}
value within a given range.

Typically, optimization involves minimizing one or more ``objectives'' or ``merit functions''. \tao
itself implements ``single objective'' optimization where there is only one merit
function\footnote{For ``multiple objective'' optimization, there is a separate program called
\vn{moga} that can be used (\sref{s:other}).}. The general form of the merit function \vn{M} in \tao
is
\begin{equation}
  {\cal M} \equiv 
    \sum_{i} w_i \, \bigl[ \delta D_i \bigr]^2 + 
    \sum_{j} w_j \, \bigl[ \delta V_j \bigr]^2
  \label{m1}
\end{equation}
where the first sum is a sum over the \vn{data} and the second sum is a sum over the \vn{variables}.
The $w_i$ and $w_j$ are weights specified by the user and, as discussed below, the $\delta D_i$ and
$\delta V_j$ are functions of the data and variables.

%------------------------------------------------------------------------
\section{Lattice Corrections}
\label{s:lattice.correction}
\index{modeling data}
\index{lattice corrections}

\index{optimization!merit function}

Consider the problem of modifying the orbit of a beam through a lattice to conform to some desired
orbit (typically this is the ``flat'' orbit running through the centers of the quadrupoles). The
process generally has three stages: First the orbit is measured, then corrections to the steering
elements are calculated (the optimization stage), and finally the corrections are applied to the
machine.

In \tao, the idea behind optimization is to vary a set of variables (steerings in the case of an
orbit correction) within the \vn{model} lattice (\sref{s:universe}) with the aim to make the data as
\vn{measured} in the machine (position data for an orbit correction) correspond to the values as
calculated from the \vn{model} lattice. In this case the $\delta D_i$ and $\delta V_j$ in \Eq{m1} will be
\begin{align}
  \delta &\tv{D}_i = \tv{data_model}_i - \tv{data_meas}_i \CRNO
  \delta &\tv{V}_j = \tv{var_model}_j - \tv{var_meas}_j
  \label{dd1}
\end{align}
\vn{data_model} is the data as calculated from the \vn{model} and \vn{data_meas} is the measured
data. \vn{var_model} is the value of a variable in the \vn{model} and \vn{var_meas} is the value as
measured at the time the data was taken (for example, by measuring the current through a steering
and using a calibration factor to calculate the kick). The $\delta V_j$ terms in the merit function
prevents degeneracies (or near degeneracies) in the problem which would allow \tao to find solutions
where \vn{data_model} matches \vn{data_measured} with the \vn{var_model} having ``unphysical''
values (values far from \vn{var_meas}). The weights $w_i$ and $w_j$ need to be set depending upon
how accurate the measured data is relative to how accurate the calibrations for measuring the
\vn{var_meas} values are. 

If the fit is good, the orbit (or whatever is being measured but for concreteness it will be assumed
here that it is the orbit that is being measured) is corrected in the machine by changing the actual
steering strengths $K_{actual}$ by an amount $dK$ given by
\begin{equation}
  dK_{j} = K_{j}^{(design)} - K_{j}^{(model)}
  \label{dkkk}
\end{equation}
where $K_{i}^{(design)}$ and $K_{i}^{(model)}$ are the \vn{design} and \vn{model} values for the
steering strengths respectively. Typically, the \vn{design} steering strengths are zero but that is
not necessary for the analysis.

\Eq{dkkk} is derived using the following logic: Once a fit to the measured data has been made, the
\vn{model} represents the actual state of the machine. On the other hand, the desired state is
represented by the \vn{design} lattice. Thus the difference $K_{i}^{(design)} - K_{i}^{(model)}$
represents ``desired - actual'' so the final state of the steering magnets after correction will be
\begin{example}
  Final_State = Initial_State + Change
              = Actual_State + (Desired_State - Actual_State)
              = Desired_State
\end{example}
There are a few points that should be kept in mind here. First, it does not matter to the
correction whether the deviations of the orbit from the ideal are caused by steering strength errors
or other errors such as dipole rolls or quadrupole offsets. To the extent that the measured orbit
can be well fit determines the extent to which the orbit can be corrected. For example, if an unwanted
kick is generated by some element at a spot that is far from any correctors, it will not be possible
to fit the measured orbit well and it will not be possible to make a good correction. If, on the
other hand, an unwanted kick is generated next to one corrector, the measured orbit can be well fit
and the \vn{model} lattice will have a strength change from the \vn{design} for that one
corrector. Varying that one corrector can then cancel out the unwanted kick.

Another point is that the correction algorithm will work with varying any set of parameters as long
as the variation in the parameters affect the \vn{model} data. Thus an analysis can be made using
dipole rolls and/or quadrupole offsets as variables or any combination thereof. If the fit is good,
rolling the dipoles and moving the quadrupoles will correct the orbit. With \tao, the User has
complete freedom to vary any parameters in the fitting process.

A third point is that the fitting process is independent of the strengths of the parameters in the
\vn{design} lattice. That is, the fit involves the actual machine state independent of what the
desired state is. It is not until the values needed for the correction are computed that the
parameter strengths in the \vn{design} lattice come into play. 

Typically, at the start of the fit, the \vn{model} lattice is, by default, equal to the \vn{design}
lattice but this is not necessary. Generally, the actual machine state is near enough to the
\vn{design} machine state so that the machine will behave roughly linearly with the variation in the
parameters (typically, if the machine parameters are far from the design values, it will not be
possible to store beam to take a measurement in the first place). This means that there will be only
one minimum merit function state so that the parameter values (steering strengths in this case) at
the end of the fit are independent of the starting state. To put this in other terms, the User
generally does not have to worry about the initial state of the \vn{model} at the start of a
fit. This is in contrast to the lattice design example in chapter~\sref{s:optimization}. With
lattice design, there are typically many local minima and it can take days of work to find a good
operating point. With lattice correction, on the other hand, the near linear nature of the problem
means that finding a solution in a machine with hundreds of correctors and hundreds of BPM readings
can be done in seconds.






Once the \vn{model} and \vn{measured} data agree, the
difference between the \vn{model} lattice, which represents the state of the machine when the
measurement is made, and the \vn{design} lattice, which represents the desired state of the machine,
is used to calculate corrections. 




In the case of flattening an orbit, the difference between the
\vn{model} steering strengths and the \vn{design} steering strengths (typically the \vn{design}
steering strengths are zero) is what the real steerings need to be changed by to flatten the orbit.

In a correction, one wants to change the machine variables so that the measured data corresponds to
the design values \vn{data_design}. For example, when ``flattening'' the orbit, \vn{data_design}
will be zero. The desired change in the data when the machine variables are varied is
\begin{example}
  desired_data_change = data_design - data_meas
\end{example}
Once a fit has been made, and presuming that the \vn{data_model} is reasonably close to the
\vn{data_meas} this desired data change within the \vn{model} lattice can be accomplished by
changing the model variables by
\begin{example}
  var_change = var_design - var_model
\end{example}
This assumes the system is linear. For many situations this is true since typically \vn{var_change}
is ``small''. Since the variables have a measured value of \vn{var_meas} the value that the
variables should be set to is
\begin{example}
  var_final = var_meas + (var_design - var_model)
\end{example}
Notice that the fitting process is independent of the \vn{design} lattice. It is only when
calculating the corrections to the variables that the \vn{design} lattice plays a role.

Sometimes it is desired to fit to changes in data as opposed to the absolute value of the
data. For example, when closing an orbit bump knob what is important is the difference in
orbits before and after the bump knob is varied. Designating one of these orbit the
\vn{reference}, the appropriate deltas to be used in \Eq{m1} are
\begin{align}
  \delta &(\tv{data_model} - \tv{data_design}) - (\tv{data_meas} - \tv{data_reference}) \CRNO
  \delta &(\tv{var_model} - \tv{var_design})  - (\tv{var_meas} - \tv{var_reference})
  \label{dd2}
\end{align}
where \vn{data_ref} and \vn{var_ref} refer to the reference measurement.  These deltas
are acceptable if the reference data is taken with the machine reasonably near the
design setup so that nonlinearities can be ignored. If this is not the case then the
fitting becomes a two step process: The first step is to fit the \vn{model} to the
\vn{reference} data using the deltas of \Eq{dd1}. The \vn{base} lattice is then set
equal to the \vn{model} lattice. The second step is to fit the model using the deltas
\begin{align}
  \delta&\tv{D} = (\tv{data_model} - \tv{data_base}) - (\tv{data_meas} - \tv{data_reference}) \CRNO
  \delta&\tv{V} = (\tv{var_model} - \tv{var_base})   - (\tv{var_meas} - \tv{var_reference})
  \label{dd3}
\end{align}

Control of what data and what variables are to be used in the fitting process is controlled by the
\vn{use}, \vn{veto}, \vn{restore}, and \vn{clip} commands.

%------------------------------------------------------------------------
\section{Lattice Design}
\label{s:lattice.design}
\index{optimization!lattice design}
\index{optimization!constraints}

Lattice design is the process of calculating \vn{variable} strengths to meet a number of criteria
called constraints. For example, one constraint could be that the beta function in some part of the
lattice not exceed a certain value. In this case, we can proceed as was done for lattice corrections
and use \Eq{m1}. Here the deltas are computed to limit values to some range so a 
delta would be of the form
\begin{equation}
  \delta D \; \text{or} \; \delta V = 
    \begin{cases}
    \tv{model} - \tv{limit}  & \tv{model $>$ Limit} \\
    0                            & \tv{otherwise}
    \end{cases}
\end{equation}
or a constraint is used to keep the \vn{model} at a certain value so the form of the constraint
would be
\begin{equation}
    \delta D \; \text{or} \; \delta V = \tv{model} - \tv{target}  
\end{equation}
Here \vn{model} is the value as calculated from the \vn{model} lattice. \vn{target} and \vn{limit}
are given by the user. Part of the optimization process is in deciding what the values should be for
any \vn{target} or \vn{limit}.

%------------------------------------------------------------------------
\section{Generalized Design}
\label{s:generalized.design}
\index{optimization!generalized merit function}

The form of the deltas used in the merit function is determined by two global logicals called
\vn{opt_with_ref} and \vn{opt_with_base} (\sref{s:globals}) as shown in Table~\ref{t:delta}.
\begin{table}[ht] 
\centering 
{\tt
\begin{tabular}{lll} \toprule
  \vn{Opt_with_ref} & \vn{Opt_with_base} & \vn{delta} \\ \midrule
  F & F & model - meas                \\
  T & F & model - meas + ref - design \\
  F & T & model - meas - base         \\
  T & T & model - meas + ref - base   \\
\bottomrule
\end{tabular}
} 
\caption{The form of \vn{delta}}  
\label{t:delta}
\end{table}
An exception occurs when using a \vn{common root lattice} (\sref{s:crl}). In this case, the common
universe does not have base or reference values associated with it. Thus all data and variables that
are associated with the common universe calculate their \vn{delta} as if both \vn{opt_with_ref} and
\vn{opt_with_base} were set to \vn{False}.

Another exception occurs with data when the datum value cannot be computed (\sref{s:datum.opt}). In
this case, the datum's \vn{invalid} value is used for the \vn{delta}. This is useful, for example,
in a linear lattice when the particle trajectory results in the particle being lost.

The \vn{Non-Zero-Condition} needed for a non--zero $D_i$ is dependent upon the \vn{merit_type} of
the datum (\sref{s:data.anatomy}).  There are seven \vn{merit_type} constraint types as given in
Table~\ref{t:con.type}.
\begin{table}[ht]
\centering
{\tt
\begin{tabular}{|l|l|l|} \toprule
  {\it Merit\_Type}         & {\it Non-zero-Condition} \\ \midrule
  \vn{target}, \vn{average} & Any \vn{delta}   \\
  \vn{max-min}              & Any \vn{delta}   \\
  \vn{min}, \vn{abs_min}    & \vn{delta} $<$ 0 \\
  \vn{max}, \vn{abs_max}    & \vn{delta} $>$ 0 \\
\bottomrule
\end{tabular}
}
\caption{Data Constraint Type List.}
\label{t:con.type}
\end{table}
\index{optimization!optimize with reference}

For variables, the form of the terms $V_i$ is determined by its \vn{merit_type}.  Here the
\vn{merit_type} may be:
\begin{example}
  target
  limit
\end{example}
A \vn{target} \vn{merit_type} for a variable is the same as for datum. In this case, \vn{model} is
just the value of the variable.  

A \vn{limit} \vn{merit_type} has the form
\begin{equation}
  \delta V = 
    \begin{cases}
    \tv{model} - \tv{high_lim}  & \tv{model} > \tv{high_lim} \\
    \tv{model} - \tv{low_lim}   & \tv{model} < \tv{low_lim} \\
    0                                & \tv{Otherwise}
    \end{cases}
\end{equation}
The default \vn{merit_type} for a variable is \vn{limit}.

Note: when doing lattice design, \vn{opt_with_ref} and \vn{opt_with_base} are both set to \vn{False}
and the \vn{target} and \vn{limit} values are identified with \vn{Meas}.

When optimizing a storage ring, If the ring is unstable so that the twiss parameters, closed orbit,
etc. cannot be computed, the contribution to the merit function from the corresponding datums is set
to zero. This tends to lower the merit function and in this case, an optimizer will never leave the
unstable region. To avoid this, an \vn{unstable.lattice} constraint (\sref{s:data.types}) must be set.

To see a list of constraints when running \tao use the \vn{show constraints} command
(\sref{s:show}). To see how a particular variable or datum is doing use the \vn{show data} or
\vn{show variable} commands.  See \sref{s:datum.opt} for details on how datums are chosen to be
included in an optimization.

%------------------------------------------------------------------------
\section{Variable Limits and Optimization}
\label{s:limit}

High (\vn{high_lim}) and low (\vn{low_lim}) limiting values can be set for any variable
(\sref{s:init.var}). If not explicitly set, \vn{high_lim} defaults to $10^{30}$ and \vn{low_lim}
defaults to $-10^{30}$. When running the optimizer, if the parameter \vn{global%var_limits_on}
(\sref{s:globals}) is \vn{True}, and if the (model) value of a variable is outside of
the range set by the limits, the value will be set to the value of the appropriate limit and the
variable's \vn{good_user} parameter (\sref{c:var}) is set to False so that no further variation by
the optimizer is done.

By default, any variable value outside of the limit range will reset. Even those variables that are
not varied by the optimizer. If this behavior is not desired, the parameter
\vn{global%only_limit_opt_vars} may be set to \vn{True}.  If this is done, only variables that the
optimizer is allowed to vary are restricted.

The \vn{global%optimizer_var_limit_warn} parameter controls whether a warning is printed when a
variable value goes past a limit.  The default is \vn{True}.

%------------------------------------------------------------------------
\section{Optimizers in Tao}
\label{s:tao.opti}
\index{optimization!optimizer}

The algorithm used to vary the \vn{model} variables to minimize \vn{M} is called an \vn{optimizer}.
In \vn{command line mode} the \vn{run} command is used to invoke an \vn{optimizer}. In \vn{single
mode} the \vn{g} key starts an optimizer. In both modes the period key (\vn{``.''}) stops the
optimization (however, the \vn{global%optimizer_allow_user_abort} parameter (\sref{s:globals}) can
be set to False to prevent this). Running an optimizer is also called ``fitting'' since one is
trying to get the \vn{model} data to be equal to the \vn{measured} data. With orbits this is also
called ``flattening'' since one generally wants to end up with an orbit that is on--axis.

The optimizer that is used can be defined when using the \vn{run} command but
the default optimizer can be set in the \tao input file by setting the
\vn{global%optimizer} component (\sref{s:globals}).

When the optimizer is run in \tao, the optimizer, after it initializes
itself, takes a number of \vn{cycles}. Each cycle consists of changing
the values of the variables the optimizer is allowed to change. The
number of steps that the optimizer will take is determined by the
parameter \vn{global%n_opti_cycles} (\sref{s:globals}). When the
optimizer initializes itself and goes through
\vn{global%n_opti_cycles}, it is said to have gone through one
\vn{loop}. After going through through \vn{global%n_opti_loops} loops,
the optimizer will automatically stop.  To immediately stop the
optimizer the period key \vn{``.''} may be pressed. Note: In
\vn{single_mode} (\sref{c:single}), \vn{n_opti_loops} is ignored and
the optimizer will loop forever.

There are currently three optimizers that can be used: 
  \begin{description}
  \index{lm optimizer}
  \item{\vn{lm}} \Newline
\vn{lm} is an optimizer based upon the Levenburg-Marquardt algorithm
as implemented in \vn{Numerical Recipes}\cite{b:nr}. This algorithm
looks at the local derivative matrix of \vn{dData/dVariable} and takes
steps in variable space accordingly. The derivative matrix is
calculated beforehand by varying all the variables by an amount set by
the variable's \vn{step} component (\sref{s:init.var}). The \vn{step}
size should be chosen large enough so that round-off errors will not
make computation of the derivatives inaccurate but the step size
should not be so large that the derivatives are effected by
nonlinearities. By default, the derivative matrix will be recalculated
each \vn{loop} but this can be changed by setting the
\vn{global%derivative_recalc} global parameter (\sref{s:globals}). The
reason to not recalculate the derivative matrix is one of time.
However, if the calculated derivative matrix is not accurate (that is,
if the variables have changed enough from the last time the matrix was
calculated and the nonlinearities in the lattice are large enough),
the \vn{lm} optimizer will not work very well.  In any case, this
method will only find local minimum.
  \index{lmdif optimizer}
  \item{\vn{lmdif}} \Newline
The \vn{lmdif} optimizer is like the \vn{lm} optimizer except that it
builds up the information it needs on the derivative matrix by
initially taking small steps over the first \vn{n} cycles where \vn{n}
is the number of variables. The advantage of this is that you do not
have to set a \vn{step} size for the variables. The disadvantage is
that for \vn{lmdif} to be useful, the number of \vn{cycles} must be
greater than the number of variables. Again, like \vn{lm}, this method
will only find local minimum.
  \index{de optimizer}
  \item{\vn{de}} \Newline
The \vn{de} optimizer stands for \vn{differential
evolution}\cite{b:de}. The advantage of this optimizer is that it
looks for global minimum. The disadvantage is that it is slow to find
the bottom of a local minimum. A good strategy sometimes when trying
to find a global minimum is to use \vn{de} in combination with \vn{lm}
or \vn{lmdif} one after the other. One important parameter with the
\vn{de} optimizer is the \vn{step} size. A larger step size means that
the optimizer will tend to explore larger areas of variable space but
the trade off is that this will make it harder to find minimum in the
locally. One good strategy is to vary the \vn{step} size to see what
is effective. Remember, the optimal step size will be different for
different problems and for different starting points. The \vn{step}
size that is appropriate of the \vn{de} optimizer will, in general, be
different from the \vn{step} size for the \vn{lm} optimizer. For this
reason, and to facilitate changing the step size, the actual step size
used by the \vn{de} optimizer is the step size given by a variable's
\vn{step} component multiplied by the global variable
\vn{global%de_lm_step_ratio}. This global variable can be varied using
the \vn{set} command (\sref{s:set}). The number of trial solutions used 
in the optimization is
\begin{example}
  population = number_of_variables * global%de_var_to_population_factor
\end{example}
There are also a number of parameters that can be set that will affect
how the optimizer works. See Section~\sref{s:globals} for more
details.
  \index{svd optimizer}
  \item{\vn{svd}} \Newline
The \vn{svd} optimizer uses a singular value decomposition
calculation.  See the description of \vn{svdfit} from Numerical
Recipes\cite{b:nr} for more details. With the \vn{svd} optimizer, the
setting of the \vn{global%n_opti_cycles} parameter is ignored. One
optimization loop consists of applying svd to the derivative matrix to
locate a new set of variable values.  If the merit function decreases
with the new set, the new values are retained and the optimization
loop is finished. If the merit function increases, and if the global
variable \vn{global%svd_retreat_on_merit_increase} is True (the
default), the variables are set to the original variable settings. In
either case, an increasing merit function will stop the execution of
additional loops.

The \vn{global%svd_cutoff} variable can be used to vary the cutoff
that SVD uses to decide what eigenvalues are sigular. See the
documentation for the Numerical Recipes routine \vn{svdfit} for more
details.
  \end{description}

%------------------------------------------------------------------------
\section{Optimization Troubleshooting Tips}
\label{s:opt.trouble}
\index{optimization troubleshooting}

Optimizations can behave in strange ways. Here are some tips on how to diagnose problems.

The \vn{show optimizer} (\sref{s:show.optimizer}) command will show global parameters
associated with optimizations. This will show some of the parameters that can be 
varied to get better convergence. One quick thing to do is to increase the number of
optimization loops and/or optimization cycles:
\begin{example}
	set global n_opti_loops = ...
	set global n_opti_cycles = ...
\end{example}

One of the first things to check is the merit function, the top contributors can be seen
with the command \vn{show merit} (\sref{s:show.merit}). And individual contributions
can be viewed using the \vn{show variable} and \vn{show data} commands.

If using an optimizer that uses the derivative matrix (\vn{lm}, \vn{geodesic_lm} and 
\vn{svd} optimizers), The variable \vn{step} sizes that are used to calculate the derivative
should be checked to make sure that the \vn{step} is not too small so that roundoff is a problem
but yet not too large so that nonlinearities make the calculation inaccurate. One way to
check that the step size is adequate for a given variable is to vary the variable using
the command \vn{change var} (\sref{s:change}). This command will print out the the change
in the merit function per change in variable which can be compared to the derivatives 
as shown with the \vn{show merit -derivative} (\sref{s:show.merit}) or the
\vn{show derivative} (\sref{s:show.derivative}) command.

%------------------------------------------------------------------------
\section{Common Root Lattice (CRL) Analysis}
\label{s:crl}
\index{common root lattice}

Some data analysis problems involve varying variables in a both the
\vn{model} and \vn{base} lattices simultaneously. Such is the case
with Orbit Response Matrix (\vn{ORM}) analysis\cite{b:orm}. With
\vn{ORM}, the analysis starts with a set of difference orbits. A given
difference orbit is generated by varying a given steering by a known
amount and the steering varied is different for different difference
orbits. Typically, The number $N$ of difference orbits is equal to the
number of steering elements in the machine. In \tao, this will result
in the creation of $N$ universes, one for each difference
measurement. The \vn{model} lattice in a universe will correspond to
the machine with the corresponding steering set to what it was when
the data was taken. Conversely, the \vn{base} lattices in all the
universes all correspond to the common condition without any steering
variation.

In \tao, this arrangement is called \vn{Common Root Lattice}
(\vn{CRL}) analysis. To do a CRL analysis, the \vn{common_lattice}
switch must be set at initialization time (\sref{s:init.lat}).  With
\vn{CRL}, \tao will set up a \vn{``common''} universe with index 0.
The \vn{model} lattice of this common universe will be used as the
\vn{base} lattice for all universes. 

The variables (fit parameters) in a \vn{CRL} analysis can be divided
into two classes. One class consists of the parameters that were
varied to get the data of the different universes. With \vn{ORM},
these are the steering strengths. At initialization
(\sref{s:init.var}), variables must be set up that control these
parameters. A single variable will control that particular parameter in
a particular universe, that was varied to create the data for that
universe. 

The second class of variables consists of everything that is
to be varied in the common root lattice. With \vn{ORM}, this generally
will include such things as quadrupole and BPM error tilts, etc. That
is, parameters that did {\em not} change during data taking. The
\tao variables that are created for these parameters will control
parameters of the \vn{model} lattice in the common universe.

To cut down on memory usage when using \vn{CRL} (the number of data
sets, hence the number of universes, can be very large), \tao does
not, except for the common \vn{model} lattice, reserve separate memory
for each \vn{model} lattice. Rather, it reserves memory for a single
\vn{``working''} lattice and the \vn{model} lattice for a particular
universe is created by first copying the common \vn{base} lattice to
the \vn{working} lattice and then applying the variable(s) (a steering
in the case of \vn{ORM}) appropriate for that universe.  As a result,
except for the common \vn{model} lattice, it is not possible to vary a
parameter of a \vn{model} lattice unless that parameter has a \tao
variable that associated with it. The \vn{change} command
(\sref{s:change}) is thus restricted to always vary parameters in
the common \vn{model} lattice.

With \vn{CRL}, the \vn{opt_with_base} and \vn{opt_with_ref}
(\sref{s:generalized.design}) global logicals are generally set to
True. Since \vn{opt_with_base}, and \vn{opt_with_ref} do not make
sense when applied to the data in the common universe, The
contribution to the merit function from data in this universe is
always calculated as if \vn{opt_with_base} and \vn{opt_with_ref} were
set to False.

With \vn{opt_with_base} set to True, the \vn{base} value for a
datum is evaluated by looking for a corresponding datum in the common
universe and using its \vn{model} value. To simplify the bookkeeping,
it is assumed that the structure of the data arrays is identical from
universe to universe. That is, the \vn{show data} command gives
identical results independent of the default universe. 
